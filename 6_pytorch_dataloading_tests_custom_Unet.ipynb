{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "torch.set_float32_matmul_precision('medium')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import random\n",
    "\n",
    "# We also set the logging level so that we get some feedback from the API\n",
    "import logging\n",
    "logging.basicConfig(level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running in /data/hpcdata/users/bryald/git/icenet/notebook-pipeline\n"
     ]
    }
   ],
   "source": [
    "# Quick hack to put us in the icenet-pipeline folder,\n",
    "# assuming it was created as per 01.cli_demonstration.ipynb\n",
    "import os\n",
    "if os.path.exists(\"pytorch_example.ipynb\"):\n",
    "    os.chdir(\"../notebook-pipeline\")\n",
    "print(\"Running in {}\".format(os.getcwd()))\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-08 02:12:08.931669: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-12-08 02:12:08.931734: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-12-08 02:12:08.933138: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "INFO:root:Loading configuration loader.notebook_api_data.json\n"
     ]
    }
   ],
   "source": [
    "from icenet.data.loaders import IceNetDataLoaderFactory\n",
    "\n",
    "implementation = \"dask\"\n",
    "loader_config = \"loader.notebook_api_data.json\"\n",
    "dataset_name = \"pytorch_notebook\"\n",
    "lag = 1\n",
    "\n",
    "dl = IceNetDataLoaderFactory().create_data_loader(\n",
    "    implementation,\n",
    "    loader_config,\n",
    "    dataset_name,\n",
    "    lag,\n",
    "    n_forecast_days=7,\n",
    "    north=False,\n",
    "    south=True,\n",
    "    output_batch_size=1,\n",
    "    generate_workers=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We generate a config only dataset, which will get saved in `dataset_config.pytorch_notebook.json`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Writing dataset configuration without data generation\n",
      "INFO:root:91 train dates in total, NOT generating cache data.\n",
      "INFO:root:21 val dates in total, NOT generating cache data.\n",
      "INFO:root:2 test dates in total, NOT generating cache data.\n",
      "INFO:root:Writing configuration to ./dataset_config.pytorch_notebook.json\n"
     ]
    }
   ],
   "source": [
    "dl.write_dataset_config_only()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now create the IceNetDataSet object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_config = \"dataset_config.pytorch_notebook.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Loading configuration dataset_config.pytorch_notebook.json\n",
      "WARNING:root:Running in configuration only mode, tfrecords were not generated for this dataset\n"
     ]
    }
   ],
   "source": [
    "from icenet.data.dataset import IceNetDataSet\n",
    "\n",
    "dataset = IceNetDataSet(dataset_config, batch_size=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom PyTorch Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class IceNetDataSetPyTorch(Dataset):\n",
    "    def __init__(self,\n",
    "                 configuration_path: str,\n",
    "                 mode: str,\n",
    "                 batch_size: int = 1,\n",
    "                 shuffling: bool = False):\n",
    "        self._ds = IceNetDataSet(configuration_path=configuration_path,\n",
    "                                 batch_size=batch_size,\n",
    "                                 shuffling=shuffling)\n",
    "        self._dl = self._ds.get_data_loader()\n",
    "\n",
    "        # check mode option\n",
    "        if mode not in [\"train\", \"val\", \"test\"]:\n",
    "            raise ValueError(\"mode must be either 'train', 'val' or 'test'\")\n",
    "        self._mode = mode\n",
    "\n",
    "        self._dates = self._dl._config[\"sources\"][\"osisaf\"][\"dates\"][self._mode]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self._ds._counts[self._mode]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # print()\n",
    "        # return tuple( map(lambda x: torch.from_numpy(x).float().contiguous(), self._dl.generate_sample(date=pd.Timestamp(self._dates[idx].replace('_', '-'))) ) )\n",
    "        return self._dl.generate_sample(date=pd.Timestamp(self._dates[idx].replace('_', '-')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Loading configuration dataset_config.pytorch_notebook.json\n",
      "WARNING:root:Running in configuration only mode, tfrecords were not generated for this dataset\n",
      "INFO:root:Loading configuration /data/hpcdata/users/bryald/git/icenet/notebook-pipeline/loader.notebook_api_data.json\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "91"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_torch = IceNetDataSetPyTorch(configuration_path=dataset_config,\n",
    "                                mode=\"train\")\n",
    "len(ds_torch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Loading configuration dataset_config.pytorch_notebook.json\n",
      "WARNING:root:Running in configuration only mode, tfrecords were not generated for this dataset\n",
      "INFO:root:Loading configuration /data/hpcdata/users/bryald/git/icenet/notebook-pipeline/loader.notebook_api_data.json\n",
      "INFO:root:Loading configuration dataset_config.pytorch_notebook.json\n",
      "WARNING:root:Running in configuration only mode, tfrecords were not generated for this dataset\n",
      "INFO:root:Loading configuration /data/hpcdata/users/bryald/git/icenet/notebook-pipeline/loader.notebook_api_data.json\n",
      "INFO:root:Loading configuration dataset_config.pytorch_notebook.json\n",
      "WARNING:root:Running in configuration only mode, tfrecords were not generated for this dataset\n",
      "INFO:root:Loading configuration /data/hpcdata/users/bryald/git/icenet/notebook-pipeline/loader.notebook_api_data.json\n"
     ]
    }
   ],
   "source": [
    "train_dataset = IceNetDataSetPyTorch(configuration_path=dataset_config, mode=\"train\")\n",
    "val_dataset = IceNetDataSetPyTorch(configuration_path=dataset_config, mode=\"val\")\n",
    "test_dataset = IceNetDataSetPyTorch(configuration_path=dataset_config, mode=\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 4\n",
    "shuffle = False\n",
    "persistent_workers=False\n",
    "num_workers = 0\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=shuffle, persistent_workers=persistent_workers, num_workers=num_workers)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=shuffle, persistent_workers=persistent_workers, num_workers=num_workers)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=shuffle, persistent_workers=persistent_workers, num_workers=num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data = iter(train_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i, data in enumerate(train_dataloader):\n",
    "#     # X, y, sample_weights\n",
    "#     print(type(data), len(data))\n",
    "#     print(data[0].shape, data[1].shape, data[2].shape)\n",
    "#     # print(data[0])\n",
    "#     if i == 2:\n",
    "#         break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i, data in enumerate(val_dataloader):\n",
    "#     # X, y, sample_weights\n",
    "#     print(type(data), len(data))\n",
    "#     # torch.Size([4, 432, 432, 9]) torch.Size([4, 432, 432, 7, 1]) torch.Size([4, 432, 432, 7, 1])\n",
    "#     print(data[0].shape, data[1].shape, data[2].shape)\n",
    "#     # print(data[0])\n",
    "#     if i == 2:\n",
    "#         break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i, data in enumerate(test_dataloader):\n",
    "#     # X, y, sample_weights\n",
    "#     print(type(data), len(data))\n",
    "#     print(data[0].shape, data[1].shape, data[2].shape)\n",
    "#     # print(data[0])\n",
    "#     if i == 2:\n",
    "#         break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# val0 = next(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# val1 = next(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try:\n",
    "#     print( iter(train_dataloader) )\n",
    "#     print(\"train_dataloader is iterable\")\n",
    "# except TypeError:\n",
    "#     print(\"train_dataloader is not iterable\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for batch_idx, (data, _) in enumerate(train_loader):\n",
    "#     # print(type(data))\n",
    "#     # print(data)\n",
    "#     # print(batch_idx)\n",
    "#     break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IceNet UNet model\n",
    "\n",
    "As a first attempt to implement a PyTorch example, we adapt code from https://github.com/ampersandmcd/icenet-gan/.\n",
    "\n",
    "Below is a PyTorch implementation of the UNet architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class UNet(nn.Module):\n",
    "    \"\"\"\n",
    "    An implementation of a UNet for pixelwise classification.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self,\n",
    "                 input_channels, \n",
    "                 filter_size=3, \n",
    "                 n_filters_factor=1, \n",
    "                 n_forecast_days=7, \n",
    "                 n_output_classes=1,\n",
    "                **kwargs):\n",
    "        super(UNet, self).__init__()\n",
    "\n",
    "        self.input_channels = input_channels\n",
    "        self.filter_size = filter_size\n",
    "        self.n_filters_factor = n_filters_factor\n",
    "        self.n_forecast_days = n_forecast_days\n",
    "        self.n_output_classes = n_output_classes\n",
    "\n",
    "        self.conv1a = nn.Conv2d(in_channels=input_channels, \n",
    "                                out_channels=int(128*n_filters_factor),\n",
    "                                kernel_size=filter_size,\n",
    "                                padding=\"same\")\n",
    "        self.conv1b = nn.Conv2d(in_channels=int(128*n_filters_factor),\n",
    "                                out_channels=int(128*n_filters_factor),\n",
    "                                kernel_size=filter_size,\n",
    "                                padding=\"same\")\n",
    "        self.bn1 = nn.BatchNorm2d(num_features=int(128*n_filters_factor))\n",
    "\n",
    "        self.conv2a = nn.Conv2d(in_channels=int(128*n_filters_factor),\n",
    "                                out_channels=int(256*n_filters_factor),\n",
    "                                kernel_size=filter_size,\n",
    "                                padding=\"same\")\n",
    "        self.conv2b = nn.Conv2d(in_channels=int(256*n_filters_factor),\n",
    "                                out_channels=int(256*n_filters_factor),\n",
    "                                kernel_size=filter_size,\n",
    "                                padding=\"same\")\n",
    "        self.bn2 = nn.BatchNorm2d(num_features=int(256*n_filters_factor))\n",
    "\n",
    "        self.conv3a = nn.Conv2d(in_channels=int(256*n_filters_factor),\n",
    "                                out_channels=int(512*n_filters_factor),\n",
    "                                kernel_size=filter_size,\n",
    "                                padding=\"same\")\n",
    "        self.conv3b = nn.Conv2d(in_channels=int(512*n_filters_factor),\n",
    "                                out_channels=int(512*n_filters_factor),\n",
    "                                kernel_size=filter_size,\n",
    "                                padding=\"same\")\n",
    "        self.bn3 = nn.BatchNorm2d(num_features=int(512*n_filters_factor))\n",
    "\n",
    "        self.conv4a = nn.Conv2d(in_channels=int(512*n_filters_factor),\n",
    "                                out_channels=int(512*n_filters_factor),\n",
    "                                kernel_size=filter_size,\n",
    "                                padding=\"same\")\n",
    "        self.conv4b = nn.Conv2d(in_channels=int(512*n_filters_factor),\n",
    "                                out_channels=int(512*n_filters_factor),\n",
    "                                kernel_size=filter_size,\n",
    "                                padding=\"same\")\n",
    "        self.bn4 = nn.BatchNorm2d(num_features=int(512*n_filters_factor))\n",
    "\n",
    "        self.conv5a = nn.Conv2d(in_channels=int(512*n_filters_factor),\n",
    "                                out_channels=int(1024*n_filters_factor),\n",
    "                                kernel_size=filter_size,\n",
    "                                padding=\"same\")\n",
    "        self.conv5b = nn.Conv2d(in_channels=int(1024*n_filters_factor),\n",
    "                                out_channels=int(1024*n_filters_factor),\n",
    "                                kernel_size=filter_size,\n",
    "                                padding=\"same\")\n",
    "        self.bn5 = nn.BatchNorm2d(num_features=int(1024*n_filters_factor))\n",
    "\n",
    "        self.conv6a = nn.Conv2d(in_channels=int(1024*n_filters_factor),\n",
    "                                out_channels=int(512*n_filters_factor),\n",
    "                                kernel_size=filter_size,\n",
    "                                padding=\"same\")\n",
    "        self.conv6b = nn.Conv2d(in_channels=int(1024*n_filters_factor),\n",
    "                                out_channels=int(512*n_filters_factor),\n",
    "                                kernel_size=filter_size,\n",
    "                                padding=\"same\")\n",
    "        self.conv6c = nn.Conv2d(in_channels=int(512*n_filters_factor),\n",
    "                                out_channels=int(512*n_filters_factor),\n",
    "                                kernel_size=filter_size,\n",
    "                                padding=\"same\")\n",
    "        self.bn6 = nn.BatchNorm2d(num_features=int(512*n_filters_factor))\n",
    "\n",
    "        self.conv7a = nn.Conv2d(in_channels=int(512*n_filters_factor),\n",
    "                                out_channels=int(512*n_filters_factor),\n",
    "                                kernel_size=filter_size,\n",
    "                                padding=\"same\")\n",
    "        self.conv7b = nn.Conv2d(in_channels=int(1024*n_filters_factor),\n",
    "                                out_channels=int(512*n_filters_factor),\n",
    "                                kernel_size=filter_size,\n",
    "                                padding=\"same\")\n",
    "        self.conv7c = nn.Conv2d(in_channels=int(512*n_filters_factor),\n",
    "                                out_channels=int(512*n_filters_factor),\n",
    "                                kernel_size=filter_size,\n",
    "                                padding=\"same\")\n",
    "        self.bn7 = nn.BatchNorm2d(num_features=int(512*n_filters_factor))\n",
    "\n",
    "        self.conv8a = nn.Conv2d(in_channels=int(512*n_filters_factor),\n",
    "                                out_channels=int(256*n_filters_factor),\n",
    "                                kernel_size=filter_size,\n",
    "                                padding=\"same\")\n",
    "        self.conv8b = nn.Conv2d(in_channels=int(512*n_filters_factor),\n",
    "                                out_channels=int(256*n_filters_factor),\n",
    "                                kernel_size=filter_size,\n",
    "                                padding=\"same\")\n",
    "        self.conv8c = nn.Conv2d(in_channels=int(256*n_filters_factor),\n",
    "                                out_channels=int(256*n_filters_factor),\n",
    "                                kernel_size=filter_size,\n",
    "                                padding=\"same\")\n",
    "        self.bn8 = nn.BatchNorm2d(num_features=int(256*n_filters_factor))\n",
    "\n",
    "        self.conv9a = nn.Conv2d(in_channels=int(256*n_filters_factor),\n",
    "                                out_channels=int(128*n_filters_factor),\n",
    "                                kernel_size=filter_size,\n",
    "                                padding=\"same\")\n",
    "        self.conv9b = nn.Conv2d(in_channels=int(256*n_filters_factor),\n",
    "                                out_channels=int(128*n_filters_factor),\n",
    "                                kernel_size=filter_size,\n",
    "                                padding=\"same\")\n",
    "        self.conv9c = nn.Conv2d(in_channels=int(128*n_filters_factor),\n",
    "                                out_channels=int(128*n_filters_factor),\n",
    "                                kernel_size=filter_size,\n",
    "                                padding=\"same\")  # no batch norm on last layer\n",
    "\n",
    "        self.final_conv = nn.Conv2d(in_channels=int(128*n_filters_factor),\n",
    "                                    out_channels=n_output_classes*n_forecast_days,\n",
    "                                    kernel_size=filter_size,\n",
    "                                    padding=\"same\")\n",
    "        \n",
    "    def forward(self, x):\n",
    "\n",
    "        # transpose from shape (b, h, w, c) to (b, c, h, w) for pytorch conv2d layers\n",
    "        x = torch.movedim(x, -1, 1)  # move c from last to second dim\n",
    "\n",
    "        # run through network\n",
    "        conv1 = self.conv1a(x)  # input to 128\n",
    "        conv1 = F.relu(conv1)\n",
    "        conv1 = self.conv1b(conv1)  # 128 to 128\n",
    "        conv1 = F.relu(conv1)\n",
    "        bn1 = self.bn1(conv1)\n",
    "        pool1 = F.max_pool2d(bn1, kernel_size=(2, 2))\n",
    "\n",
    "        conv2 = self.conv2a(pool1)  # 128 to 256\n",
    "        conv2 = F.relu(conv2)\n",
    "        conv2 = self.conv2b(conv2)  # 256 to 256\n",
    "        conv2 = F.relu(conv2)\n",
    "        bn2 = self.bn2(conv2)\n",
    "        pool2 = F.max_pool2d(bn2, kernel_size=(2, 2))\n",
    "\n",
    "        conv3 = self.conv3a(pool2)  # 256 to 512\n",
    "        conv3 = F.relu(conv3)\n",
    "        conv3 = self.conv3b(conv3)  # 512 to 512\n",
    "        conv3 = F.relu(conv3)\n",
    "        bn3 = self.bn3(conv3)\n",
    "        pool3 = F.max_pool2d(bn3, kernel_size=(2, 2))\n",
    "\n",
    "        conv4 = self.conv4a(pool3)  # 512 to 512\n",
    "        conv4 = F.relu(conv4)\n",
    "        conv4 = self.conv4b(conv4)  # 512 to 512\n",
    "        conv4 = F.relu(conv4)\n",
    "        bn4 = self.bn4(conv4)\n",
    "        pool4 = F.max_pool2d(bn4, kernel_size=(2, 2))\n",
    "\n",
    "        conv5 = self.conv5a(pool4)  # 512 to 1024\n",
    "        conv5 = F.relu(conv5)\n",
    "        conv5 = self.conv5b(conv5)  # 1024 to 1024\n",
    "        conv5 = F.relu(conv5)\n",
    "        bn5 = self.bn5(conv5)\n",
    "\n",
    "        up6 = F.interpolate(bn5, scale_factor=2, mode=\"nearest\")\n",
    "        up6 = self.conv6a(up6)  # 1024 to 512\n",
    "        up6 = F.relu(up6)\n",
    "        merge6 = torch.cat([bn4, up6], dim=1) # 512 and 512 to 1024 along c dimension\n",
    "        conv6 = self.conv6b(merge6)  # 1024 to 512\n",
    "        conv6 = F.relu(conv6)\n",
    "        conv6 = self.conv6c(conv6)  # 512 to 512\n",
    "        conv6 = F.relu(conv6)\n",
    "        bn6 = self.bn6(conv6)\n",
    "\n",
    "        up7 = F.interpolate(bn6, scale_factor=2, mode=\"nearest\")\n",
    "        up7 = self.conv7a(up7)  # 1024 to 512\n",
    "        up7 = F.relu(up7)\n",
    "        merge7 = torch.cat([bn3, up7], dim=1) # 512 and 512 to 1024 along c dimension\n",
    "        conv7 = self.conv7b(merge7)  # 1024 to 512\n",
    "        conv7 = F.relu(conv7)\n",
    "        conv7 = self.conv7c(conv7)  # 512 to 512\n",
    "        conv7 = F.relu(conv7)\n",
    "        bn7 = self.bn7(conv7)\n",
    "\n",
    "        up8 = F.interpolate(bn7, scale_factor=2, mode=\"nearest\")\n",
    "        up8 = self.conv8a(up8)  # 512 to 256\n",
    "        up8 = F.relu(up8)\n",
    "        merge8 = torch.cat([bn2, up8], dim=1) # 256 and 256 to 512 along c dimension\n",
    "        conv8 = self.conv8b(merge8)  # 512 to 256\n",
    "        conv8 = F.relu(conv8)\n",
    "        conv8 = self.conv8c(conv8)  # 256 to 256\n",
    "        conv8 = F.relu(conv8)\n",
    "        bn8 = self.bn8(conv8)\n",
    "\n",
    "        up9 = F.interpolate(bn8, scale_factor=2, mode=\"nearest\")\n",
    "        up9 = self.conv9a(up9)  # 256 to 128\n",
    "        up9 = F.relu(up9)\n",
    "        merge9 = torch.cat([bn1, up9], dim=1) # 128 and 128 to 256 along c dimension\n",
    "        conv9 = self.conv9b(merge9)  # 256 to 128\n",
    "        conv9 = F.relu(conv9)\n",
    "        conv9 = self.conv9c(conv9)  # 128 to 128\n",
    "        conv9 = F.relu(conv9)  # no batch norm on last layer\n",
    " \n",
    "        final_layer_logits = self.final_conv(conv9)\n",
    "\n",
    "        # transpose from shape (b, c, h, w) back to (b, h, w, c) to align with training data\n",
    "        final_layer_logits = torch.movedim(final_layer_logits, 1, -1)  # move c from second to final dim\n",
    "        b, h, w, c = final_layer_logits.shape\n",
    "\n",
    "\n",
    "        # unpack c=classes*days dimension into classes, days as separate dimensions\n",
    "        final_layer_logits = final_layer_logits.reshape((b, h, w, self.n_output_classes, self.n_forecast_days))\n",
    "\n",
    "        # output = F.softmax(final_layer_logits, dim=-2)  # apply over n_output_classes dimension\n",
    "        output = F.sigmoid(final_layer_logits) # Single output class.\n",
    "\n",
    "        # print(f\"Final layer shape: {output.shape}\")\n",
    "        # print(f\"self.n_output_classes: {self.n_output_classes}\")\n",
    "\n",
    "        return output  # shape (b, h, w, c, t)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = UNet(\n",
    "#     input_channels=train_dataset._ds._config[\"num_channels\"],\n",
    "#     filter_size=3,\n",
    "#     n_filters_factor=1,\n",
    "#     n_forecast_days=train_dataset._ds._config[\"n_forecast_days\"]\n",
    "# )\n",
    "\n",
    "# # Print the model architecture\n",
    "# print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# import torch.nn.functional as F\n",
    "\n",
    "# # class UNetBatchNorm(nn.Module):\n",
    "# class UNet(nn.Module):\n",
    "#     def __init__(self, input_channels, filter_size=3, n_filters_factor=1, n_forecast_days=6):\n",
    "#         super(UNet, self).__init__()\n",
    "#         self.input_channels = input_channels\n",
    "#         self.filter_size = filter_size\n",
    "#         self.n_filters_factor = n_filters_factor\n",
    "#         self.n_output_classes = 1\n",
    "#         self.n_forecast_days = n_forecast_days\n",
    "\n",
    "#         # Encoder\n",
    "#         self.conv1 = self.conv_block(input_channels, int(64 * n_filters_factor))\n",
    "#         self.conv2 = self.conv_block(int(64 * n_filters_factor), int(128 * n_filters_factor))\n",
    "#         self.conv3 = self.conv_block(int(128 * n_filters_factor), int(256 * n_filters_factor))\n",
    "#         self.conv4 = self.conv_block(int(256 * n_filters_factor), int(256 * n_filters_factor))\n",
    "#         self.conv5 = self.conv_block(int(256 * n_filters_factor), int(512 * n_filters_factor))\n",
    "\n",
    "#         # Decoder\n",
    "#         self.up6 = self.upconv_block(int(512 * n_filters_factor), int(256 * n_filters_factor))\n",
    "#         self.up7 = self.upconv_block(int(256 * n_filters_factor), int(256 * n_filters_factor))\n",
    "#         self.up8 = self.upconv_block(int(256 * n_filters_factor), int(128 * n_filters_factor))\n",
    "#         self.up9 = self.upconv_block(int(128 * n_filters_factor), int(64 * n_filters_factor))\n",
    "\n",
    "#         # Final layer\n",
    "#         self.final_layer = nn.Conv2d(int(64 * n_filters_factor), n_forecast_days, kernel_size=1)\n",
    "\n",
    "#     def conv_block(self, in_channels, out_channels, kernel_size=3):\n",
    "#         return nn.Sequential(\n",
    "#             nn.Conv2d(in_channels, out_channels, kernel_size, padding=\"same\"),\n",
    "#             nn.ReLU(inplace=True),\n",
    "#             nn.Conv2d(out_channels, out_channels, kernel_size, padding=\"same\"),\n",
    "#             nn.ReLU(inplace=True),\n",
    "#             nn.BatchNorm2d(out_channels)\n",
    "#         )\n",
    "\n",
    "#     def upconv_block(self, in_channels, out_channels, kernel_size=2):\n",
    "#         return nn.Sequential(\n",
    "#             nn.ConvTranspose2d(in_channels, out_channels, kernel_size, stride=2),\n",
    "#             nn.ReLU(inplace=True)\n",
    "#         )\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         n_filters_factor = self.n_filters_factor\n",
    "\n",
    "#         # transpose from shape (b, h, w, c) to (b, c, h, w) for pytorch conv2d layers\n",
    "#         x = torch.movedim(x, -1, 1)  # move c from last to second dim\n",
    "\n",
    "#         # Encoder\n",
    "#         conv1 = self.conv1(x)\n",
    "#         pool1 = F.max_pool2d(conv1, 2)\n",
    "\n",
    "#         conv2 = self.conv2(pool1)\n",
    "#         pool2 = F.max_pool2d(conv2, 2)\n",
    "\n",
    "#         conv3 = self.conv3(pool2)\n",
    "#         pool3 = F.max_pool2d(conv3, 2)\n",
    "\n",
    "#         conv4 = self.conv4(pool3)\n",
    "#         pool4 = F.max_pool2d(conv4, 2)\n",
    "\n",
    "#         conv5 = self.conv5(pool4)\n",
    "\n",
    "#         # Decoder\n",
    "#         up6 = self.up6(conv5)\n",
    "#         print(\"Input shape:\", up6.shape)\n",
    "#         merge6 = torch.cat([conv4, up6], dim=1)\n",
    "#         print(\"Output shape:\", merge6.shape)\n",
    "#         conv6 = self.conv_block(int(512 * n_filters_factor), int(256 * n_filters_factor))(merge6)\n",
    "\n",
    "#         up7 = self.up7(conv6)\n",
    "#         merge7 = torch.cat([conv3, up7], dim=1)\n",
    "#         conv7 = self.conv_block(int(256 * n_filters_factor), int(256 * n_filters_factor))(merge7)\n",
    "\n",
    "#         up8 = self.up8(conv7)\n",
    "#         merge8 = torch.cat([conv2, up8], dim=1)\n",
    "#         conv8 = self.conv_block(int(256 * n_filters_factor), int(128 * n_filters_factor))(merge8)\n",
    "\n",
    "#         up9 = self.up9(conv8)\n",
    "#         merge9 = torch.cat([conv1, up9], dim=1)\n",
    "#         conv9 = self.conv_block(int(128 * n_filters_factor), int(64 * n_filters_factor))(merge9)\n",
    "\n",
    "#         # Final layer\n",
    "#         output = self.final_layer(conv9)\n",
    "\n",
    "#         # transpose from shape (b, c, h, w) back to (b, h, w, c) to align with training data\n",
    "#         output = torch.movedim(output, 1, -1)  # move c from second to final dim\n",
    "\n",
    "#         return output\n",
    "\n",
    "# # # Instantiate the model\n",
    "# # input_channels = train_dataset._ds._config[\"num_channels\"]  # Adjust based on your input data\n",
    "# # n_forecast_days = 7\n",
    "# # n_filters_factor = 1\n",
    "# # filter_size = 3\n",
    "# # model = UNet(input_channels, filter_size, n_filters_factor, n_forecast_days)\n",
    "\n",
    "# # # Print the model architecture\n",
    "# # print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchmetrics import Metric\n",
    "\n",
    "class IceNetAccuracy(Metric):\n",
    "    \"\"\"Binary accuracy metric for use at multiple leadtimes.\n",
    "\n",
    "    Reference: https://lightning.ai/docs/torchmetrics/stable/pages/implement.html\n",
    "    \"\"\"    \n",
    "\n",
    "    # Set class properties\n",
    "    is_differentiable: bool = False\n",
    "    higher_is_better: bool = True\n",
    "    full_state_update: bool = True\n",
    "\n",
    "    def __init__(self, leadtimes_to_evaluate: list):\n",
    "        \"\"\"Custom loss/metric for binary accuracy in classifying SIC>15% for multiple leadtimes.\n",
    "\n",
    "        Args:\n",
    "            leadtimes_to_evaluate: A list of leadtimes to consider\n",
    "                e.g., [0, 1, 2, 3, 4, 5] to consider first six days in accuracy computation or\n",
    "                e.g., [0] to only look at the first day's accuracy\n",
    "                e.g., [5] to only look at the sixth day's accuracy\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.leadtimes_to_evaluate = leadtimes_to_evaluate\n",
    "        self.add_state(\"weighted_score\", default=torch.tensor(0.), dist_reduce_fx=\"sum\")\n",
    "        self.add_state(\"possible_score\", default=torch.tensor(0.), dist_reduce_fx=\"sum\")\n",
    "\n",
    "    def update(self, preds: torch.Tensor, target: torch.Tensor, sample_weight: torch.Tensor):\n",
    "        # preds and target are shape (b, h, w, t)\n",
    "        # sum marginal and full ice for binary eval\n",
    "        preds = (preds > 0.15).long() # torch.Size([2, 432, 432, 7])\n",
    "        target = (target > 0.15).long() # torch.Size([2, 432, 432, 7])\n",
    "        # sample_weight = sample_weight.squeeze(dim=-1) # torch.Size([2, 432, 432, 7, 1]) to torch.Size([2, 432, 432, 7])\n",
    "        # print(f\"preds shape: {preds.shape}\")\n",
    "        # print(f\"target shape: {target.shape}\")\n",
    "        # print(f\"sample_weight shape: {sample_weight.squeeze(dim=-1).shape}\")\n",
    "        base_score = preds[:, :, :, self.leadtimes_to_evaluate] == target[:, :, :, self.leadtimes_to_evaluate]\n",
    "        self.weighted_score += torch.sum(base_score * sample_weight[:, :, :, self.leadtimes_to_evaluate])\n",
    "        self.possible_score += torch.sum(sample_weight[:, :, :, self.leadtimes_to_evaluate])\n",
    "\n",
    "    def compute(self):\n",
    "        return self.weighted_score.float() / self.possible_score * 100.0\n",
    "\n",
    "\n",
    "class SIEError(Metric):\n",
    "    \"\"\"\n",
    "    Sea Ice Extent error metric (in km^2) for use at multiple leadtimes.\n",
    "    \"\"\" \n",
    "\n",
    "    # Set class properties\n",
    "    is_differentiable: bool = False\n",
    "    higher_is_better: bool = False\n",
    "    full_state_update: bool = True\n",
    "\n",
    "    def __init__(self, leadtimes_to_evaluate: list):\n",
    "        \"\"\"Construct an SIE error metric (in km^2) for use at multiple leadtimes.\n",
    "            leadtimes_to_evaluate: A list of leadtimes to consider\n",
    "                e.g., [0, 1, 2, 3, 4, 5] to consider six days in computation or\n",
    "                e.g., [0] to only look at the first day\n",
    "                e.g., [5] to only look at the sixth day\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.leadtimes_to_evaluate = leadtimes_to_evaluate\n",
    "        self.add_state(\"pred_sie\", default=torch.tensor(0.), dist_reduce_fx=\"sum\")\n",
    "        self.add_state(\"true_sie\", default=torch.tensor(0.), dist_reduce_fx=\"sum\")\n",
    "\n",
    "    def update(self, preds: torch.Tensor, target: torch.Tensor, sample_weight: torch.Tensor):\n",
    "        # preds and target are shape (b, h, w, t)\n",
    "        # sum marginal and full ice for binary eval\n",
    "        preds = (preds > 0.0).long()\n",
    "        target = (target > 0.0).long()\n",
    "        self.pred_sie += preds[:, :, :, self.leadtimes_to_evaluate].sum()\n",
    "        self.true_sie += target[:, :, :, self.leadtimes_to_evaluate].sum()\n",
    "\n",
    "    def compute(self):\n",
    "        return (self.pred_sie - self.true_sie) * 25**2 # each pixel is 25x25 km"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A _LightningModule_ wrapper for UNet model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import lightning.pytorch as pl\n",
    "# from torchmetrics import MetricCollection\n",
    "\n",
    "# class LitUNet(pl.LightningModule):\n",
    "#     \"\"\"\n",
    "#     A LightningModule wrapping the UNet implementation of IceNet.\n",
    "#     \"\"\"\n",
    "#     def __init__(self,\n",
    "#                  model: nn.Module,\n",
    "#                  criterion: callable,\n",
    "#                  learning_rate: float):\n",
    "#         \"\"\"\n",
    "#         Construct a UNet LightningModule.\n",
    "#         Note that we keep hyperparameters separate from dataloaders to prevent data leakage at test time.\n",
    "#         :param model: PyTorch model\n",
    "#         :param criterion: PyTorch loss function for training instantiated with reduction=\"none\"\n",
    "#         :param learning_rate: Float learning rate for our optimiser\n",
    "#         \"\"\"\n",
    "#         super().__init__()\n",
    "#         self.model = model\n",
    "#         self.criterion = criterion\n",
    "#         self.learning_rate = learning_rate\n",
    "#         self.n_output_classes = model.n_output_classes  # this should be a property of the network\n",
    "\n",
    "#         metrics = {\n",
    "#             \"val_accuracy\": IceNetAccuracy(leadtimes_to_evaluate=list(range(self.model.n_forecast_days))),\n",
    "#             \"val_sieerror\": SIEError(leadtimes_to_evaluate=list(range(self.model.n_forecast_days)))\n",
    "#         }\n",
    "#         for i in range(self.model.n_forecast_days):\n",
    "#             metrics[f\"val_accuracy_{i}\"] = IceNetAccuracy(leadtimes_to_evaluate=[i])\n",
    "#             metrics[f\"val_sieerror_{i}\"] = SIEError(leadtimes_to_evaluate=[i])\n",
    "#         self.metrics = MetricCollection(metrics)\n",
    "\n",
    "#         test_metrics = {\n",
    "#             \"test_accuracy\": IceNetAccuracy(leadtimes_to_evaluate=list(range(self.model.n_forecast_days))),\n",
    "#             \"test_sieerror\": SIEError(leadtimes_to_evaluate=list(range(self.model.n_forecast_days)))\n",
    "#         }\n",
    "#         for i in range(self.model.n_forecast_days):\n",
    "#             test_metrics[f\"test_accuracy_{i}\"] = IceNetAccuracy(leadtimes_to_evaluate=[i])\n",
    "#             test_metrics[f\"test_sieerror_{i}\"] = SIEError(leadtimes_to_evaluate=[i])\n",
    "#         self.test_metrics = MetricCollection(test_metrics)\n",
    "\n",
    "#         self.save_hyperparameters(ignore=[\"model\", \"criterion\"])\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         \"\"\"\n",
    "#         Implement forward function.\n",
    "#         :param x: Inputs to model.\n",
    "#         :return: Outputs of model.\n",
    "#         \"\"\"\n",
    "#         return self.model(x)\n",
    "\n",
    "#     def training_step(self, batch):\n",
    "#         \"\"\"\n",
    "#         Perform a pass through a batch of training data.\n",
    "#         Apply pixel-weighted loss by manually reducing.\n",
    "#         See e.g. https://discuss.pytorch.org/t/unet-pixel-wise-weighted-loss-function/46689/5.\n",
    "#         :param batch: Batch of input, output, weight triplets\n",
    "#         :param batch_idx: Index of batch\n",
    "#         :return: Loss from this batch of data for use in backprop\n",
    "#         \"\"\"\n",
    "#         x, y, sample_weight = batch\n",
    "#         y_hat = self.model(x)\n",
    "#         # BNU: Move forecast one dim over\n",
    "#         y = torch.movedim(y, -1, -2)\n",
    "#         sample_weight = torch.movedim(sample_weight, -1, -2)\n",
    "#         # print(f\"y batch shape: {y.shape}\")\n",
    "#         # print(f\"y_hat final output shape: {y_hat.shape}\")\n",
    "#         # print(f\"sample_weight shape: {sample_weight.shape}\")\n",
    "#         # y and y_hat are shape (b, h, w, c, t) but loss expects (b, c, h, w, t)\n",
    "#         # note that criterion needs reduction=\"none\" for weighting to work\n",
    "#         # training_step()\n",
    "#         if isinstance(self.criterion, nn.CrossEntropyLoss):  # requires int class encoding\n",
    "#             loss = self.criterion(y_hat.movedim(-2, 1), y.argmax(-2).long())\n",
    "#         else:  # requires one-hot encoding\n",
    "#             loss = self.criterion(y_hat.movedim(-2, 1), y.movedim(-2, 1))\n",
    "#         loss = torch.mean(loss * sample_weight.movedim(-2, 1))\n",
    "#         self.log(\"train_loss\", loss, sync_dist=True)\n",
    "#         return loss\n",
    "\n",
    "#     def validation_step(self, batch):\n",
    "#         x, y, sample_weight = batch\n",
    "#         y_hat = self.model(x)\n",
    "#         # BNU: Move forecast one dim over\n",
    "#         y = torch.movedim(y, -1, -2)\n",
    "#         sample_weight = torch.movedim(sample_weight, -1, -2)\n",
    "#         # y and y_hat are shape (b, h, w, c, t) but loss expects (b, c, h, w, t)\n",
    "#         # note that criterion needs reduction=\"none\" for weighting to work\n",
    "#         # validation_step()\n",
    "#         if isinstance(self.criterion, nn.CrossEntropyLoss):  # requires int class encoding\n",
    "#             loss = self.criterion(y_hat.movedim(-2, 1), y.argmax(-2).long())\n",
    "#         else:  # requires one-hot encoding\n",
    "#             loss = self.criterion(y_hat.movedim(-2, 1), y.movedim(-2, 1))\n",
    "#         loss = torch.mean(loss * sample_weight.movedim(-2, 1))\n",
    "#         self.log(\"val_loss\", loss, on_step=False, on_epoch=True, sync_dist=True)  # epoch-level loss\n",
    "#         y_hat_pred = y_hat.argmax(dim=-2).long()  # argmax over c where shape is (b, h, w, c, t)\n",
    "#         self.metrics.update(y_hat_pred, y.argmax(dim=-2).long(), sample_weight.squeeze(dim=-2))  # shape (b, h, w, t)\n",
    "#         return loss\n",
    "\n",
    "#     def on_validation_epoch_end(self):\n",
    "#         self.log_dict(self.metrics.compute(), on_step=False, on_epoch=True, sync_dist=True)  # epoch-level metrics\n",
    "#         self.metrics.reset()\n",
    "\n",
    "#     def test_step(self, batch):\n",
    "#         x, y, sample_weight = batch\n",
    "#         y_hat = self.model(x)\n",
    "#         # BNU: Move forecast one dim over\n",
    "#         y = torch.movedim(y, -1, -2)\n",
    "#         sample_weight = torch.movedim(sample_weight, -1, -2)\n",
    "#         # y and y_hat are shape (b, h, w, c, t) but loss expects (b, c, h, w, t)\n",
    "#         # note that criterion needs reduction=\"none\" for weighting to work\n",
    "#         # test_step()\n",
    "#         if isinstance(self.criterion, nn.CrossEntropyLoss):  # requires int class encoding\n",
    "#             loss = self.criterion(y_hat.movedim(-2, 1), y.argmax(-2).long())\n",
    "#         else:  # requires one-hot encoding\n",
    "#             loss = self.criterion(y_hat.movedim(-2, 1), y.movedim(-2, 1))\n",
    "#         loss = torch.mean(loss * sample_weight.movedim(-2, 1))\n",
    "#         self.log(\"test_loss\", loss, on_step=False, on_epoch=True, sync_dist=True)  # epoch-level loss\n",
    "#         y_hat_pred = y_hat.argmax(dim=-2)  # argmax over c where shape is (b, h, w, c, t)\n",
    "#         self.test_metrics.update(y_hat_pred, y.argmax(dim=-2).long(), sample_weight.squeeze(dim=-2))  # shape (b, h, w, t)\n",
    "#         return loss\n",
    "\n",
    "#     def on_test_epoch_end(self):\n",
    "#         self.log_dict(self.test_metrics.compute(),on_step=False, on_epoch=True, sync_dist=True)  # epoch-level metrics\n",
    "#         self.test_metrics.reset()\n",
    "\n",
    "#     def configure_optimizers(self):\n",
    "#         optimizer = torch.optim.Adam(self.parameters(), lr=self.learning_rate)\n",
    "#         return {\n",
    "#             \"optimizer\": optimizer\n",
    "#         }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightning.pytorch as pl\n",
    "from lightning.pytorch.utilities.types import TRAIN_DATALOADERS\n",
    "from torchmetrics import MetricCollection\n",
    "\n",
    "class LitUNet(pl.LightningModule):\n",
    "    \"\"\"\n",
    "    A LightningModule wrapping the UNet implementation of IceNet.\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 model: nn.Module,\n",
    "                 criterion: callable,\n",
    "                 learning_rate: float):\n",
    "        \"\"\"\n",
    "        Construct a UNet LightningModule.\n",
    "        Note that we keep hyperparameters separate from dataloaders to prevent data leakage at test time.\n",
    "        :param model: PyTorch model\n",
    "        :param criterion: PyTorch loss function for training instantiated with reduction=\"none\"\n",
    "        :param learning_rate: Float learning rate for our optimiser\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "        self.criterion = criterion\n",
    "        self.learning_rate = learning_rate\n",
    "        self.n_output_classes = model.n_output_classes  # this should be a property of the network\n",
    "\n",
    "        metrics = {\n",
    "            \"val_accuracy\": IceNetAccuracy(leadtimes_to_evaluate=list(range(self.model.n_forecast_days))),\n",
    "            \"val_sieerror\": SIEError(leadtimes_to_evaluate=list(range(self.model.n_forecast_days)))\n",
    "        }\n",
    "        for i in range(self.model.n_forecast_days):\n",
    "            metrics[f\"val_accuracy_{i}\"] = IceNetAccuracy(leadtimes_to_evaluate=[i])\n",
    "            metrics[f\"val_sieerror_{i}\"] = SIEError(leadtimes_to_evaluate=[i])\n",
    "        self.metrics = MetricCollection(metrics)\n",
    "\n",
    "        test_metrics = {\n",
    "            \"test_accuracy\": IceNetAccuracy(leadtimes_to_evaluate=list(range(self.model.n_forecast_days))),\n",
    "            \"test_sieerror\": SIEError(leadtimes_to_evaluate=list(range(self.model.n_forecast_days)))\n",
    "        }\n",
    "        for i in range(self.model.n_forecast_days):\n",
    "            test_metrics[f\"test_accuracy_{i}\"] = IceNetAccuracy(leadtimes_to_evaluate=[i])\n",
    "            test_metrics[f\"test_sieerror_{i}\"] = SIEError(leadtimes_to_evaluate=[i])\n",
    "        self.test_metrics = MetricCollection(test_metrics)\n",
    "\n",
    "        self.save_hyperparameters(ignore=[\"model\", \"criterion\"])\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Implement forward function.\n",
    "        :param x: Inputs to model.\n",
    "        :return: Outputs of model.\n",
    "        \"\"\"\n",
    "        return self.model(x)\n",
    "\n",
    "    def training_step(self, batch):\n",
    "        \"\"\"\n",
    "        Perform a pass through a batch of training data.\n",
    "        Apply pixel-weighted loss by manually reducing.\n",
    "        See e.g. https://discuss.pytorch.org/t/unet-pixel-wise-weighted-loss-function/46689/5.\n",
    "        :param batch: Batch of input, output, weight triplets\n",
    "        :param batch_idx: Index of batch\n",
    "        :return: Loss from this batch of data for use in backprop\n",
    "        \"\"\"\n",
    "        x, y, sample_weight = batch\n",
    "        y_hat = self.model(x)\n",
    "        # print(f\"x shape: {x.shape}\")\n",
    "        # print(f\"y shape: {y.shape}\")\n",
    "        # print(f\"sample_weight shape: {sample_weight.shape}\")\n",
    "        # print(f\"y_hat shape: {y_hat.shape}\")\n",
    "\n",
    "        # BNU: Move forecast one dim over\n",
    "        # y = torch.movedim(y, -1, -2)\n",
    "        # sample_weight = torch.movedim(sample_weight, -1, -2)\n",
    "\n",
    "        # print(f\"y batch shape: {y.shape}\")\n",
    "        # print(f\"y_hat final output shape: {y_hat.shape}\")\n",
    "        # print(f\"sample_weight shape: {sample_weight.shape}\")\n",
    "        # y and y_hat are shape (b, h, w, c, t) but loss expects (b, c, h, w, t)\n",
    "        # note that criterion needs reduction=\"none\" for weighting to work\n",
    "        # training_step()\n",
    "        # if isinstance(self.criterion, nn.CrossEntropyLoss):  # requires int class encoding\n",
    "        #     loss = self.criterion(y_hat.movedim(-2, 1), y.argmax(-2).long())\n",
    "        # else:  # requires one-hot encoding\n",
    "        #     loss = self.criterion(y_hat.movedim(-2, 1), y.movedim(-2, 1))\n",
    "\n",
    "        # Use weighted mean squared error as loss function, matching IceNet 2.\n",
    "        # Mean squared error of SIC (%) (float)\n",
    "        loss = self.criterion(y_hat.movedim(-2, 1)*100, y.movedim(-1, 1)*100)\n",
    "        loss = torch.mean(loss * sample_weight.movedim(-2, 1))\n",
    "        self.log(\"train_loss\", loss, on_step=True, on_epoch=True, prog_bar=True, sync_dist=True)\n",
    "        return {'loss': loss}\n",
    "\n",
    "    def validation_step(self, batch):\n",
    "        # x, y, sample_weight = batch\n",
    "        # y_hat = self.model(x)\n",
    "        # # BNU: Move forecast one dim over\n",
    "        # y = torch.movedim(y, -1, -2)\n",
    "        # sample_weight = torch.movedim(sample_weight, -1, -2)\n",
    "        # # y and y_hat are shape (b, h, w, c, t) but loss expects (b, c, h, w, t)\n",
    "        # # note that criterion needs reduction=\"none\" for weighting to work\n",
    "        # # validation_step()\n",
    "        # if isinstance(self.criterion, nn.CrossEntropyLoss):  # requires int class encoding\n",
    "        #     loss = self.criterion(y_hat.movedim(-2, 1), y.argmax(-2).long())\n",
    "        # else:  # requires one-hot encoding\n",
    "        #     loss = self.criterion(y_hat.movedim(-2, 1), y.movedim(-2, 1))\n",
    "        # loss = torch.mean(loss * sample_weight.movedim(-2, 1))\n",
    "\n",
    "        x, y, sample_weight = batch\n",
    "        y_hat = self.model(x)\n",
    "        # Use weighted mean squared error as loss function, matching IceNet 2.\n",
    "        # Mean squared error of SIC (%) (float)\n",
    "        loss = self.criterion(y_hat.movedim(-2, 1)*100, y.movedim(-1, 1)*100)\n",
    "        loss = torch.mean(loss * sample_weight.movedim(-2, 1))\n",
    "\n",
    "        self.log(\"val_loss\", loss, on_step=False, on_epoch=True, prog_bar=True, sync_dist=True)  # epoch-level loss\n",
    "        y_hat_pred = y_hat.argmax(dim=-2).long()  # argmax over c where shape is (b, h, w, c, t)\n",
    "        self.metrics.update(y_hat_pred, y.argmax(dim=-1).long(), sample_weight.squeeze(dim=-1))  # shape (b, h, w, t)\n",
    "        return loss\n",
    "\n",
    "    def on_validation_epoch_end(self):\n",
    "        self.log_dict(self.metrics.compute(), on_step=False, prog_bar=True, sync_dist=True)  # epoch-level metrics\n",
    "        self.metrics.reset()\n",
    "\n",
    "    def test_step(self, batch):\n",
    "        x, y, sample_weight = batch\n",
    "        y_hat = self.model(x)\n",
    "        # Use weighted mean squared error as loss function, matching IceNet 2.\n",
    "        # Mean squared error of SIC (%) (float)\n",
    "        loss = self.criterion(y_hat.movedim(-2, 1)*100, y.movedim(-1, 1)*100)\n",
    "        loss = torch.mean(loss * sample_weight.movedim(-2, 1))\n",
    "\n",
    "        self.log(\"test_loss\", loss, on_step=False, on_epoch=True, prog_bar=True, sync_dist=True)  # epoch-level loss\n",
    "        y_hat_pred = y_hat.argmax(dim=-2)  # argmax over c where shape is (b, h, w, c, t)\n",
    "        self.test_metrics.update(y_hat_pred, y.argmax(dim=-1).long(), sample_weight.squeeze(dim=-1))  # shape (b, h, w, t)\n",
    "        return loss\n",
    "\n",
    "    def on_test_epoch_end(self):\n",
    "        self.log_dict(self.test_metrics.compute(),on_step=False, on_epoch=True, sync_dist=True)  # epoch-level metrics\n",
    "        self.test_metrics.reset()\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=self.learning_rate)\n",
    "        return {\n",
    "            \"optimizer\": optimizer\n",
    "        }\n",
    "\n",
    "    # def train_dataloader(self) -> TRAIN_DATALOADERS:\n",
    "    #     return super().train_dataloader()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function for training UNet model using PyTorch Lightning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightning.pytorch.callbacks import ModelCheckpoint\n",
    "\n",
    "def train_icenet(configuration_path,\n",
    "                 learning_rate,\n",
    "                 max_epochs,\n",
    "                 batch_size,\n",
    "                 n_workers,\n",
    "                 filter_size,\n",
    "                 n_filters_factor,\n",
    "                 seed):\n",
    "    \"\"\"\n",
    "    Train IceNet using the arguments specified in the `args` namespace.\n",
    "    :param args: Namespace of configuration parameters\n",
    "    \"\"\"\n",
    "    # init\n",
    "    pl.seed_everything(seed)\n",
    "    \n",
    "    # configure datasets and dataloaders\n",
    "    train_dataset = IceNetDataSetPyTorch(configuration_path, mode=\"train\")\n",
    "    val_dataset = IceNetDataSetPyTorch(configuration_path, mode=\"val\")\n",
    "    train_dataloader = DataLoader(train_dataset, batch_size=batch_size, num_workers=n_workers,\n",
    "                                  persistent_workers=True, shuffle=False)\n",
    "    val_dataloader = DataLoader(val_dataset, batch_size=batch_size, num_workers=n_workers,\n",
    "                                persistent_workers=True, shuffle=False)\n",
    "\n",
    "    # print(\"Input train shapes: \")\n",
    "    # for batch in train_dataloader:\n",
    "    #     [print(batch[i].shape, end='') for i in range(3)]\n",
    "    # print()\n",
    "\n",
    "    # print(\"Input val shapes: \")\n",
    "    # for batch in val_dataloader:\n",
    "    #     [print(batch[i].shape, end='') for i in range(3)]\n",
    "    # print()\n",
    "\n",
    "    # construct unet\n",
    "    model = UNet(\n",
    "        input_channels=train_dataset._ds._config[\"num_channels\"],\n",
    "        filter_size=filter_size,\n",
    "        n_filters_factor=n_filters_factor,\n",
    "        n_forecast_days=train_dataset._ds._config[\"n_forecast_days\"]\n",
    "    )\n",
    "    \n",
    "    # criterion = nn.CrossEntropyLoss(reduction=\"none\")\n",
    "    criterion = nn.MSELoss(reduction=\"none\")\n",
    "    # from torchvision.ops.focal_loss import sigmoid_focal_loss\n",
    "    # criterion = sigmoid_focal_loss\n",
    "    \n",
    "    # configure PyTorch Lightning module\n",
    "    lit_module = LitUNet(\n",
    "        model=model,\n",
    "        criterion=criterion,\n",
    "        learning_rate=learning_rate\n",
    "    )\n",
    "\n",
    "    # set up trainer configuration\n",
    "    trainer = pl.Trainer(\n",
    "        accelerator=\"auto\",\n",
    "        devices=1,\n",
    "        log_every_n_steps=10,\n",
    "        max_epochs=max_epochs,\n",
    "        num_sanity_val_steps=1,\n",
    "        fast_dev_run=True, # Runs single batch through train and validation\n",
    "    )\n",
    "    trainer.callbacks.append(ModelCheckpoint(monitor=\"val_accuracy\", mode=\"max\"))\n",
    "\n",
    "    # train model\n",
    "    print(f\"Training {len(train_dataset)} examples / {len(train_dataloader)} batches (batch size {batch_size}).\")\n",
    "    print(f\"Validating {len(val_dataset)} examples / {len(val_dataloader)} batches (batch size {batch_size}).\")\n",
    "    trainer.fit(lit_module, train_dataloader, val_dataloader)\n",
    "\n",
    "    return model, trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Seed set to 45\n",
      "INFO:lightning.fabric.utilities.seed:Seed set to 45\n",
      "INFO:root:Loading configuration dataset_config.pytorch_notebook.json\n",
      "WARNING:root:Running in configuration only mode, tfrecords were not generated for this dataset\n",
      "INFO:root:Loading configuration /data/hpcdata/users/bryald/git/icenet/notebook-pipeline/loader.notebook_api_data.json\n",
      "INFO:root:Loading configuration dataset_config.pytorch_notebook.json\n",
      "WARNING:root:Running in configuration only mode, tfrecords were not generated for this dataset\n",
      "INFO:root:Loading configuration /data/hpcdata/users/bryald/git/icenet/notebook-pipeline/loader.notebook_api_data.json\n",
      "/data/hpcdata/users/bryald/miniconda3/envs/pytorch/lib/python3.11/site-packages/lightning/fabric/plugins/environments/slurm.py:191: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /data/hpcdata/users/bryald/miniconda3/envs/pytorch/l ...\n",
      "INFO: GPU available: True (cuda), used: True\n",
      "INFO:lightning.pytorch.utilities.rank_zero:GPU available: True (cuda), used: True\n",
      "INFO: TPU available: False, using: 0 TPU cores\n",
      "INFO:lightning.pytorch.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
      "INFO: IPU available: False, using: 0 IPUs\n",
      "INFO:lightning.pytorch.utilities.rank_zero:IPU available: False, using: 0 IPUs\n",
      "INFO: HPU available: False, using: 0 HPUs\n",
      "INFO:lightning.pytorch.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
      "INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training 91 examples / 23 batches (batch size 4).\n",
      "Validating 21 examples / 6 batches (batch size 4).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightning.pytorch.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "INFO: \n",
      "  | Name         | Type             | Params\n",
      "--------------------------------------------------\n",
      "0 | model        | UNet             | 12.1 M\n",
      "1 | criterion    | MSELoss          | 0     \n",
      "2 | metrics      | MetricCollection | 0     \n",
      "3 | test_metrics | MetricCollection | 0     \n",
      "--------------------------------------------------\n",
      "12.1 M    Trainable params\n",
      "0         Non-trainable params\n",
      "12.1 M    Total params\n",
      "48.435    Total estimated model params size (MB)\n",
      "INFO:lightning.pytorch.callbacks.model_summary:\n",
      "  | Name         | Type             | Params\n",
      "--------------------------------------------------\n",
      "0 | model        | UNet             | 12.1 M\n",
      "1 | criterion    | MSELoss          | 0     \n",
      "2 | metrics      | MetricCollection | 0     \n",
      "3 | test_metrics | MetricCollection | 0     \n",
      "--------------------------------------------------\n",
      "12.1 M    Trainable params\n",
      "0         Non-trainable params\n",
      "12.1 M    Total params\n",
      "48.435    Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|| 23/23 [00:23<00:00,  0.96it/s, v_num=118, train_loss_step=9.580, val_loss=59.40, val_accuracy=100.0, val_accuracy_0=100.0, val_accuracy_1=100.0, val_accuracy_2=100.0, val_accuracy_3=100.0, val_accuracy_4=100.0, val_accuracy_5=100.0, val_accuracy_6=100.0, val_sieerror=0.000, val_sieerror_0=0.000, val_sieerror_1=0.000, val_sieerror_2=0.000, val_sieerror_3=0.000, val_sieerror_4=0.000, val_sieerror_5=0.000, val_sieerror_6=0.000, train_loss_epoch=7.750]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: `Trainer.fit` stopped: `max_epochs=10` reached.\n",
      "INFO:lightning.pytorch.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|| 23/23 [00:24<00:00,  0.94it/s, v_num=118, train_loss_step=9.580, val_loss=59.40, val_accuracy=100.0, val_accuracy_0=100.0, val_accuracy_1=100.0, val_accuracy_2=100.0, val_accuracy_3=100.0, val_accuracy_4=100.0, val_accuracy_5=100.0, val_accuracy_6=100.0, val_sieerror=0.000, val_sieerror_0=0.000, val_sieerror_1=0.000, val_sieerror_2=0.000, val_sieerror_3=0.000, val_sieerror_4=0.000, val_sieerror_5=0.000, val_sieerror_6=0.000, train_loss_epoch=7.750]\n"
     ]
    }
   ],
   "source": [
    "seed = 45\n",
    "model, trainer = train_icenet(configuration_path=dataset_config,\n",
    "             learning_rate=1e-4,\n",
    "             max_epochs=10,\n",
    "             batch_size=4,\n",
    "             n_workers=4,\n",
    "             filter_size=3,\n",
    "             n_filters_factor=0.5,\n",
    "             seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Loading configuration dataset_config.pytorch_notebook.json\n",
      "WARNING:root:Running in configuration only mode, tfrecords were not generated for this dataset\n",
      "INFO:root:Loading configuration /data/hpcdata/users/bryald/git/icenet/notebook-pipeline/loader.notebook_api_data.json\n",
      "/data/hpcdata/users/bryald/miniconda3/envs/pytorch/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/checkpoint_connector.py:145: `.test(ckpt_path=None)` was called without a model. The best model of the previous `fit` call will be used. You can pass `.test(ckpt_path='best')` to use the best model or `.test(ckpt_path='last')` to use the last model. If you pass a value, this warning will be silenced.\n",
      "/data/hpcdata/users/bryald/miniconda3/envs/pytorch/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/checkpoint_connector.py:156: `.test(ckpt_path=\"best\")` is called with Trainer configured with multiple `ModelCheckpoint` callbacks. It will use the best checkpoint path from first checkpoint callback.\n",
      "INFO: Restoring states from the checkpoint path at /data/hpcdata/users/bryald/git/icenet/notebook-pipeline/lightning_logs/version_118/checkpoints/epoch=9-step=230.ckpt\n",
      "INFO:lightning.pytorch.utilities.rank_zero:Restoring states from the checkpoint path at /data/hpcdata/users/bryald/git/icenet/notebook-pipeline/lightning_logs/version_118/checkpoints/epoch=9-step=230.ckpt\n",
      "INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "INFO:lightning.pytorch.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "INFO: Loaded model weights from the checkpoint at /data/hpcdata/users/bryald/git/icenet/notebook-pipeline/lightning_logs/version_118/checkpoints/epoch=9-step=230.ckpt\n",
      "INFO:lightning.pytorch.utilities.rank_zero:Loaded model weights from the checkpoint at /data/hpcdata/users/bryald/git/icenet/notebook-pipeline/lightning_logs/version_118/checkpoints/epoch=9-step=230.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|| 1/1 [00:00<00:00,  4.61it/s]\n",
      "\n",
      "       Test metric             DataLoader 0\n",
      "\n",
      "      test_accuracy                100.0\n",
      "     test_accuracy_0               100.0\n",
      "     test_accuracy_1               100.0\n",
      "     test_accuracy_2               100.0\n",
      "     test_accuracy_3               100.0\n",
      "     test_accuracy_4               100.0\n",
      "     test_accuracy_5               100.0\n",
      "     test_accuracy_6               100.0\n",
      "        test_loss           14.042448997497559\n",
      "      test_sieerror                 0.0\n",
      "     test_sieerror_0                0.0\n",
      "     test_sieerror_1                0.0\n",
      "     test_sieerror_2                0.0\n",
      "     test_sieerror_3                0.0\n",
      "     test_sieerror_4                0.0\n",
      "     test_sieerror_5                0.0\n",
      "     test_sieerror_6                0.0\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'test_loss': 14.042448997497559,\n",
       "  'test_accuracy': 100.0,\n",
       "  'test_accuracy_0': 100.0,\n",
       "  'test_accuracy_1': 100.0,\n",
       "  'test_accuracy_2': 100.0,\n",
       "  'test_accuracy_3': 100.0,\n",
       "  'test_accuracy_4': 100.0,\n",
       "  'test_accuracy_5': 100.0,\n",
       "  'test_accuracy_6': 100.0,\n",
       "  'test_sieerror': 0.0,\n",
       "  'test_sieerror_0': 0.0,\n",
       "  'test_sieerror_1': 0.0,\n",
       "  'test_sieerror_2': 0.0,\n",
       "  'test_sieerror_3': 0.0,\n",
       "  'test_sieerror_4': 0.0,\n",
       "  'test_sieerror_5': 0.0,\n",
       "  'test_sieerror_6': 0.0}]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset = IceNetDataSetPyTorch(configuration_path=dataset_config, mode=\"test\")\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=4, shuffle=False, persistent_workers=True, num_workers=4)\n",
    "\n",
    "# automatically load the best weights\n",
    "trainer.test(dataloaders=test_dataloader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
